%YAML 1.2
---
name: '23042019kb1-64x6-Q05-SE2'       # ideally no spaces
gpu: 0                                 # gpu id to process on

dataset: 
  num_chunks: 120000                   # newest nof chunks to parse
  train_ratio: 0.90                    # trainingset ratio
  # For separated test and train data.
  input_train: '/home/daniel/Documents/train/trainingdata/supervised-*/' # supports glob
  input_test: '/home/daniel/Documents/train/trainingdata/supervised-5/'  # supports glob
  # For a one-shot run with all data in one directory.
  # input: '/path/to/chunks/*/draw/'

training:
    batch_size: 2048                   # training batch
    total_steps: 70000                # terminate after these steps
    test_steps: 2000                   # eval test set values after this many steps
    checkpoint_steps: 5000             # optional frequency for checkpointing before finish
    shuffle_size: 250000               # size of the shuffle buffer
    lr_values:                         # list of learning rates
        - 0.1
        - 0.05
        - 0.02
        - 0.002
        - 0.0005
    lr_boundaries:                     # list of boundaries
        - 10000
        - 20000
        - 100000
        - 130000
    policy_loss_weight: 1.0            # weight of policy loss
    value_loss_weight: 1.0             # weight of value loss
    path: '/home/daniel/Documents/train'    # network storage dir
    q_ratio: 0.5
    train_avg_report_steps: 500

model:
  filters: 64
  residual_blocks: 6
  se_ratio: 2
  value: 'classical'
...

